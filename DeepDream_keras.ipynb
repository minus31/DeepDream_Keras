{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Dream "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Deep Dream`은 2015년, 구글에서 발표된, CNN을 이용한 Image modification 기술이다. 아래의 그림과 같이 마치 꿈 속에서의 그림 처럼 보이고, 사진에서 벌레나, 개, 새 등의 사물이 추상적으로 표현된다는 특징 덕분에, 당시 인터넷에 크게 유행 하기도 했다. \n",
    "\n",
    "`Deep Dream`은 기존의 CNN의 필터를 시각화하는 작업과 맥을 같이 한다. `Deep Dream`은 아래와 같은 특징을 가지고 있다. \n",
    "\n",
    "  1. 전역적 경사 상승 법(Gradient Ascent)\n",
    "    - CNN 필터를 시각화 하기 위해서, Convolutional Layer의 Output을 최대화 하는, Gradient Ascent 방법을 사용했다. `Deep Dream` 에서는 특정 레이어에만 이를 적용하는 것이 아니라, 다수의 레이어에 대해 적용하여, 많은 특징들을 한번에 표현하려 했다. \n",
    "  2. 실제 이미지를 입력\n",
    "    - 빈 이미지나, 잡음이 심한 이미지로 부터 시각화 하는 것이 아니라, 실제 이미지로 부터 시각화 하기 때문에, 원래의 이미지의 시각적 패턴을 잘 가지게 되었다. \n",
    "  3. 여러 크기의 이미지를 처리 \n",
    "    - 좀 더 나은 결과를 위해, 여러 크기의 이미지를 처리 하였다. \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Pretrained model\n",
    "\n",
    "from keras.applications import inception_v3\n",
    "from keras import backend as K\n",
    "from keras.preprocessing import image\n",
    "import tensorflow as tf\n",
    "\n",
    "K.set_learning_phase(0) \n",
    "\n",
    "model = inception_v3.InceptionV3(include_top=False, weights='imagenet')\n",
    "# include_top : 마지막 Fully Connectted layer를 포함하여 불러올것인가를 설정하는 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Variable += will be deprecated. Use variable.assign_add if you want assignment to the variable value or 'x = x + y' if you want a new python Tensor object.\n"
     ]
    }
   ],
   "source": [
    "# loss에 반영할 레이어 와 그에 해당하는 가중치 \n",
    "layer_contributions = {\n",
    "    'mixed2': 0.2,\n",
    "    'mixed3': 3.,\n",
    "    'mixed4': 2.,\n",
    "    'mixed5': 1.5,\n",
    "}\n",
    "\n",
    "layer_dict = dict([(layer.name, layer) for layer in model.layers])\n",
    "\n",
    "loss = K.variable(0.)\n",
    "\n",
    "for layer_name in layer_contributions:\n",
    "    \n",
    "    # Add the L2 norm of the features of a layer to the loss.\n",
    "    coeff = layer_contributions[layer_name]\n",
    "    x = layer_dict[layer_name].output\n",
    "\n",
    "    # We avoid border artifacts by only involving non-border pixels in the loss.\n",
    "    scaling = K.prod(K.cast(K.shape(x), 'float32'))\n",
    "    \n",
    "    loss += coeff * K.sum(K.square(x[:, 2:-2, 2:-2, :])) / scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dream = model.input\n",
    "\n",
    "grads = K.gradients(loss, dream)[0]\n",
    "\n",
    "grads /= K.maximum(K.mean(K.abs(grads)), 1e-7)\n",
    "\n",
    "outputs = [loss, grads]\n",
    "\n",
    "fetch_loss_and_grads = K.Function([dream], outputs)\n",
    "\n",
    "def eval_loss_and_grads(x):\n",
    "    outs = fetch_loss_and_grads([x])  ## outputs \n",
    "    loss_value = outs[0]\n",
    "    grad_values = outs[1]\n",
    "    return loss_value, grad_values\n",
    "\n",
    "#### -> 그냥 이렇게, loss_value, grad_values = fetch_loss_and_grads([dream])\n",
    "\n",
    "def gradient_ascent(x, iterations, step, max_loss=None):\n",
    "\n",
    "    for i in range(iterations):\n",
    "        loss_value, grad_values = eval_loss_and_grads(x)\n",
    "        if max_loss is not None and loss_value > max_loss:\n",
    "            break\n",
    "        print('...Loss value at', i, ':', loss_value)\n",
    "        x += step * grad_values\n",
    "    return x\n",
    "\n",
    "def resize_img(img, size):\n",
    "    img = np.copy(img)\n",
    "    factors = (1, float(size[0]) / img.shape[1], float(size[1]) / img.shape[2], 1)\n",
    "    return sp.ndimage.zoom(img, factors, order=1)\n",
    "\n",
    "def save_img(img, fname):\n",
    "    pil_img = deprocess_image(np.copy(img))\n",
    "    sp.misc.imsave(fname, pil_img)\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    img = image.load_img(image_path)\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = inception_v3.preprocess_input(img)\n",
    "    \n",
    "    return img\n",
    "\n",
    "def deprocess_image(x):\n",
    "    \n",
    "    x = x.reshape((x.shape[1], x.shape[2], 3))\n",
    "    \n",
    "    x /= 2.\n",
    "    x += 0.5\n",
    "    x *= 255.\n",
    "    x = np.clip(x, 0, 255).astype(\"uint8\")\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image shape (395, 395)\n",
      "...Loss value at 0 : 0.00011823373\n",
      "...Loss value at 1 : 0.000121185716\n",
      "...Loss value at 2 : 0.00012419512\n",
      "...Loss value at 3 : 0.00012726638\n",
      "...Loss value at 4 : 0.00013041019\n",
      "...Loss value at 5 : 0.00013361704\n",
      "...Loss value at 6 : 0.0001368889\n",
      "...Loss value at 7 : 0.00014023352\n",
      "...Loss value at 8 : 0.00014365124\n",
      "...Loss value at 9 : 0.00014715707\n",
      "...Loss value at 10 : 0.00015074346\n",
      "...Loss value at 11 : 0.00015440988\n",
      "...Loss value at 12 : 0.00015816561\n",
      "...Loss value at 13 : 0.00016203013\n",
      "...Loss value at 14 : 0.00016599047\n",
      "...Loss value at 15 : 0.00017003718\n",
      "...Loss value at 16 : 0.00017418477\n",
      "...Loss value at 17 : 0.00017843887\n",
      "...Loss value at 18 : 0.00018281411\n",
      "...Loss value at 19 : 0.00018728059\n",
      "...Loss value at 20 : 0.00019186373\n",
      "...Loss value at 21 : 0.00019654006\n",
      "...Loss value at 22 : 0.00020131815\n",
      "...Loss value at 23 : 0.0002061883\n",
      "...Loss value at 24 : 0.00021116347\n",
      "...Loss value at 25 : 0.00021625064\n",
      "...Loss value at 26 : 0.00022146491\n",
      "...Loss value at 27 : 0.00022679684\n",
      "...Loss value at 28 : 0.00023223713\n",
      "...Loss value at 29 : 0.00023781495\n",
      "Processing image shape (554, 554)\n",
      "...Loss value at 0 : 0.00012365417\n",
      "...Loss value at 1 : 0.00012529486\n",
      "...Loss value at 2 : 0.00012695139\n",
      "...Loss value at 3 : 0.00012862416\n",
      "...Loss value at 4 : 0.00013031237\n",
      "...Loss value at 5 : 0.0001320166\n",
      "...Loss value at 6 : 0.00013373709\n",
      "...Loss value at 7 : 0.00013547069\n",
      "...Loss value at 8 : 0.00013722226\n",
      "...Loss value at 9 : 0.00013899467\n",
      "...Loss value at 10 : 0.00014078875\n",
      "...Loss value at 11 : 0.00014260523\n",
      "...Loss value at 12 : 0.00014444574\n",
      "...Loss value at 13 : 0.00014630852\n",
      "...Loss value at 14 : 0.00014819692\n",
      "...Loss value at 15 : 0.00015010795\n",
      "...Loss value at 16 : 0.0001520413\n",
      "...Loss value at 17 : 0.00015399433\n",
      "...Loss value at 18 : 0.00015597025\n",
      "...Loss value at 19 : 0.00015797155\n",
      "...Loss value at 20 : 0.00015999874\n",
      "...Loss value at 21 : 0.00016205212\n",
      "...Loss value at 22 : 0.00016412829\n",
      "...Loss value at 23 : 0.00016623025\n",
      "...Loss value at 24 : 0.00016835777\n",
      "...Loss value at 25 : 0.00017050948\n",
      "...Loss value at 26 : 0.00017268797\n",
      "...Loss value at 27 : 0.00017489126\n",
      "...Loss value at 28 : 0.00017712127\n",
      "...Loss value at 29 : 0.00017937952\n",
      "Processing image shape (776, 776)\n",
      "...Loss value at 0 : 0.00013175294\n",
      "...Loss value at 1 : 0.00013258675\n",
      "...Loss value at 2 : 0.0001334232\n",
      "...Loss value at 3 : 0.00013426243\n",
      "...Loss value at 4 : 0.00013510627\n",
      "...Loss value at 5 : 0.00013595421\n",
      "...Loss value at 6 : 0.0001368068\n",
      "...Loss value at 7 : 0.00013766372\n",
      "...Loss value at 8 : 0.00013852486\n",
      "...Loss value at 9 : 0.00013938965\n",
      "...Loss value at 10 : 0.00014025817\n",
      "...Loss value at 11 : 0.00014113064\n",
      "...Loss value at 12 : 0.00014200885\n",
      "...Loss value at 13 : 0.00014289204\n",
      "...Loss value at 14 : 0.0001437796\n",
      "...Loss value at 15 : 0.00014467162\n",
      "...Loss value at 16 : 0.00014556794\n",
      "...Loss value at 17 : 0.00014646954\n",
      "...Loss value at 18 : 0.00014737618\n",
      "...Loss value at 19 : 0.00014828754\n",
      "...Loss value at 20 : 0.0001492039\n",
      "...Loss value at 21 : 0.0001501248\n",
      "...Loss value at 22 : 0.00015105127\n",
      "...Loss value at 23 : 0.00015198281\n",
      "...Loss value at 24 : 0.00015291924\n",
      "...Loss value at 25 : 0.00015386012\n",
      "...Loss value at 26 : 0.0001548061\n",
      "...Loss value at 27 : 0.00015575674\n",
      "...Loss value at 28 : 0.00015671305\n",
      "...Loss value at 29 : 0.00015767457\n"
     ]
    }
   ],
   "source": [
    "#### Parameters ####\n",
    "K.get_session().run(tf.global_variables_initializer())\n",
    "step = 0.01\n",
    "num_octave = 3\n",
    "octave_scale = 1.4\n",
    "iterations = 30\n",
    "max_loss = 10.\n",
    "fname = 'result_deepdream.png'\n",
    "\n",
    "from skimage import data\n",
    "\n",
    "# # img = data.chelsea()\n",
    "# img = sp.misc.face()\n",
    "# img = image.img_to_array(img)\n",
    "# img = np.expand_dims(img, axis=0)\n",
    "# img = inception_v3.preprocess_input(img)\n",
    "\n",
    "img = preprocess_image(\"./deepdream_parc.png\")\n",
    "\n",
    "original_shape = img.shape[1:3]\n",
    "successive_shapes = [original_shape]\n",
    "\n",
    "for i in range(1, num_octave):\n",
    "    shape = tuple([int(dim / (octave_scale**i)) for dim in original_shape])\n",
    "    successive_shapes.append(shape)\n",
    "\n",
    "successive_shapes = successive_shapes[::-1] # 스케일 리스트 \n",
    "\n",
    "original_img = np.copy(img)\n",
    "shrunk_original_img = resize_img(img, successive_shapes[0]) # starting from smallest image\n",
    "\n",
    "for shape in successive_shapes:\n",
    "    \n",
    "    print('Processing image shape', shape)\n",
    "    \n",
    "    img = resize_img(img, shape)\n",
    "    \n",
    "    img = gradient_ascent(img, iterations=iterations, step=step, max_loss=max_loss)\n",
    "\n",
    "    upscaled_shrunk_original_img = resize_img(shrunk_original_img, shape)\n",
    "\n",
    "    same_size_original = resize_img(original_img, shape)\n",
    "    \n",
    "    lost_detail = same_size_original - upscaled_shrunk_original_img\n",
    "    \n",
    "    img += lost_detail\n",
    "    \n",
    "    shrunk_original_img = resize_img(original_img, shape)\n",
    "    \n",
    "# plt.imshow(deprocess_image(img))\n",
    "# image.save_img('result_deepdream.png', deprocess_image(img))\n",
    "save_img(img, fname)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
