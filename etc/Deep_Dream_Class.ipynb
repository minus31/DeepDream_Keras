{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load Pretrained model\n",
    "\n",
    "# import keras\n",
    "# from keras.models import Model\n",
    "# from keras.applications import inception_v3\n",
    "# from keras import backend as K\n",
    "# from keras.preprocessing import image\n",
    "# import tensorflow as tf\n",
    "\n",
    "# K.set_learning_phase(0)\n",
    "\n",
    "# input_shape = (1, 776, 776, 3)\n",
    "# input_tensor = tf.placeholder(tf.float32, input_shape)\n",
    "\n",
    "# model = inception_v3.InceptionV3(\n",
    "#     include_top=False, weights='imagenet', input_tensor=input_tensor)\n",
    "\n",
    "# # K.set_session(tf.session().run(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.applications import inception_v3\n",
    "from keras import backend as K\n",
    "from keras.preprocessing import image\n",
    "import tensorflow as tf\n",
    "\n",
    "K.set_learning_phase(0)\n",
    "\n",
    "\n",
    "class DeepDream():\n",
    "    \n",
    "    def __init__(self, image_path):\n",
    "        self.image_path = image_path\n",
    "        self.sess = tf.Session()\n",
    "        self.setting_sess()\n",
    "        self.model = inception_v3.InceptionV3(\n",
    "            include_top=False, weights='imagenet')\n",
    "        self.model_weights = self.model.get_weights()\n",
    "\n",
    "        self.layer_contributions = {'mixed2': 0.2,\n",
    "                                    'mixed3': 3., 'mixed4': 2., 'mixed5': 1.5}\n",
    "        self.loss = K.variable(0.)\n",
    "        self.max_loss = 10.\n",
    "        self.setting_sess()\n",
    "        self.main()\n",
    "\n",
    "    def setting_sess(self):\n",
    "        K.set_session(self.sess)\n",
    "\n",
    "    def loss_func(self):\n",
    "        for name in self.layer_contributions:\n",
    "            coef = self.layer_contributions[name]\n",
    "            x = self.model.get_layer(name=name).output\n",
    "            scaling = K.prod(K.cast(K.shape(x), 'float32'))\n",
    "            self.loss += coef * K.sum(K.square(x[:, 2:-2, 2:-2, :])) / scaling\n",
    "\n",
    "    def grad_loss_eval(self):\n",
    "        self.dream = self.model.input\n",
    "        \n",
    "        self.loss_func()\n",
    "\n",
    "        self.grads = K.gradients(self.loss, self.dream)[0]\n",
    "\n",
    "        outputs = [self.loss, self.grads]\n",
    "        self.fetch_loss_and_grads = K.Function(inputs=[self.dream], outputs=outputs)\n",
    "\n",
    "    def eval_loss_and_grads(self, x):\n",
    "        self.setting_sess()\n",
    "        self.grad_loss_eval()\n",
    "        outs = self.fetch_loss_and_grads([x])  # outputs\n",
    "        loss_value = outs[0]\n",
    "        grad_values = outs[1]\n",
    "        return loss_value, grad_values\n",
    "\n",
    "    def gradient_ascent(self, x, iterations, step, max_loss=None):\n",
    "\n",
    "        for i in range(iterations):\n",
    "            loss_value, grad_values = self.eval_loss_and_grads(x)\n",
    "\n",
    "            if max_loss is not None and loss_value > max_loss:\n",
    "                break\n",
    "            print('...Loss value at', i, ':', loss_value)\n",
    "            x += step * grad_values\n",
    "        return x\n",
    "\n",
    "    def resize_img(self, img, size):\n",
    "        img = np.copy(img)\n",
    "        factors = (1, float(size[0]) / img.shape[1],\n",
    "                   float(size[1]) / img.shape[2], 1)\n",
    "        return sp.ndimage.zoom(img, factors, order=1)\n",
    "\n",
    "    def save_img(self, img, fname):\n",
    "        pil_img = self.deprocess_image(np.copy(img))\n",
    "        sp.misc.imsave(fname, pil_img)\n",
    "\n",
    "    def preprocess_image(self, image_path):\n",
    "        img = image.load_img(image_path)\n",
    "        img = image.img_to_array(img)\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        img = inception_v3.preprocess_input(img)\n",
    "\n",
    "        return img\n",
    "\n",
    "    def deprocess_image(self, x):\n",
    "\n",
    "        x = x.reshape((x.shape[1], x.shape[2], 3))\n",
    "\n",
    "        x /= 2.\n",
    "        x += 0.5\n",
    "        x *= 255.\n",
    "        x = np.clip(x, 0, 255).astype(\"uint8\")\n",
    "        return x\n",
    "\n",
    "    def main(self):\n",
    "        \n",
    "#         K.get_session().run(tf.global_variables_initializer())\n",
    "\n",
    "#         uninit = K.get_session().run(tf.report_uninitialized_variables())\n",
    "#         def assign_op():\n",
    "#             for i, v in zip(uninit, self.model_weights):\n",
    "#                 assign_op = i.assign(v)\n",
    "        \n",
    "#                 K.get_session().run(assign_op)\n",
    "#         assign_op()\n",
    "        \n",
    "#         uninitialized_vars = []\n",
    "#         for var in tf.global_variables():\n",
    "#             try:\n",
    "#                 K.get_session().run(var)\n",
    "#             except tf.errors.FailedPreconditionError:\n",
    "#                 uninitialized_vars.append(var)\n",
    "                \n",
    "#         for i in uninitialized_vars:\n",
    "#             for v in self.model_weights:\n",
    "#                 try :\n",
    "#                     init_new_vars_op = tf.assign(i, v)\n",
    "#                     K.get_session().run(init_new_vars_op)\n",
    "#                 except:\n",
    "#                     continue\n",
    "\n",
    "\n",
    "        K.get_session().run(tf.keras.applications.InceptionV3(include_top=False, weights='imagenet'))\n",
    "\n",
    "        step = 0.01\n",
    "        num_octave = 3\n",
    "        octave_scale = 1.4\n",
    "        iterations = 30\n",
    "        max_loss = 10.\n",
    "\n",
    "        img = self.preprocess_image(self.image_path)\n",
    "\n",
    "        original_shape = img.shape[1:3]\n",
    "        successive_shapes = [original_shape]\n",
    "\n",
    "        for i in range(1, num_octave):\n",
    "            shape = tuple([int(dim / (octave_scale**i))\n",
    "                           for dim in original_shape])\n",
    "            successive_shapes.append(shape)\n",
    "\n",
    "        successive_shapes = successive_shapes[::-1]  # 스케일 리스트\n",
    "\n",
    "        original_img = np.copy(img)\n",
    "        # starting from smallest image\n",
    "        shrunk_original_img = self.resize_img(img, successive_shapes[0])\n",
    "\n",
    "        for shape in successive_shapes:\n",
    "\n",
    "            print('Processing image shape', shape)\n",
    "\n",
    "            img = self.resize_img(img, shape)\n",
    "\n",
    "            img = self.gradient_ascent(img, iterations=iterations,\n",
    "                                  step=step, max_loss=max_loss)\n",
    "\n",
    "            upscaled_shrunk_original_img = self.resize_img(\n",
    "                shrunk_original_img, shape)\n",
    "\n",
    "            same_size_original = self.resize_img(original_img, shape)\n",
    "\n",
    "            lost_detail = same_size_original - upscaled_shrunk_original_img\n",
    "\n",
    "            img += lost_detail\n",
    "\n",
    "            shrunk_original_img = self.resize_img(original_img, shape)\n",
    "\n",
    "        # plt.imshow(deprocess_image(img))\n",
    "        # image.save_img('result_deepdream.png', deprocess_image(img))\n",
    "        self.save_img(img, fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deap_dream = DeepDream(\"./deepdream_parc.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.applications.VGG16(include_top=False, weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 26)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(weights).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers[0].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path):\n",
    "        img = image.load_img(image_path)\n",
    "        img = image.img_to_array(img)\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        img = inception_v3.preprocess_input(img)\n",
    "        return img\n",
    "\n",
    "def forward_propagation(layers_output, W, b):\n",
    "    \"\"\"\n",
    "    layers_output -> next_layers input \n",
    "    \"\"\"\n",
    "    return W(layers_output + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-726a8b1bd978>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayers\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mlayers_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_propagation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 0)"
     ]
    }
   ],
   "source": [
    "layers_input = preprocess_image(\"./deepdream_parc.png\")\n",
    "\n",
    "for layer in layers :\n",
    "    W, b = layer.get_weights()\n",
    "    layers_input = forward_propagation(layers_input, W, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(layers_output, W, b):\n",
    "    \"\"\"\n",
    "    layers_output -> next_layers input \n",
    "    \"\"\"\n",
    "    \n",
    "    return W(layers_output + b)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
